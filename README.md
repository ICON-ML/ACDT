# Research Paper
https://aclanthology.org/2023.icon-1.39.pdf

# Citation
@inproceedings{reshma-etal-2023-mitigating, <br/>
    title = "Mitigating Abusive Comment Detection in {T}amil Text: A Data Augmentation Approach with Transformer Model", <br/>
    author = "Reshma, Sheik  and <br/>
      Raghavan, Balanathan  and <br/>
      Jaya Nirmala, S.", <br/>
    editor = "Jyoti, D. Pawar  and <br/>
      Sobha, Lalitha Devi", <br/>
    booktitle = "Proceedings of the 20th International Conference on Natural Language Processing (ICON)", <br/>
    month = dec, <br/>
    year = "2023", <br/>
    address = "Goa University, Goa, India", <br/>
    publisher = "NLP Association of India (NLPAI)", <br/>
    url = "https://aclanthology.org/2023.icon-1.39", <br/>
    pages = "460--465", <br/>
    abstract = "With the increasing number of users on social media platforms, the detection and categorization of abusive comments have become crucial, necessitating effective strategies to mitigate their impact on online discussions. However, the intricate and diverse nature of lowresource Indic languages presents a challenge in developing reliable detection methodologies. This research focuses on the task of classifying YouTube comments written in Tamil language into various categories. To achieve this, our research conducted experiments utilizing various multi-lingual transformer-based models along with data augmentation approaches involving back translation approaches and other pre-processing techniques. Our work provides valuable insights into the effectiveness of various preprocessing methods for this classification task. Our experiments showed that the Multilingual Representations for Indian Languages (MURIL) transformer model, coupled with round-trip translation and lexical replacement, yielded the most promising results, showcasing a significant improvement of over 15 units in macro F1-score compared to existing baselines. This contribution adds to the ongoing research to mitigate the adverse impact of abusive content on online platforms, emphasizing the utilization of diverse preprocessing strategies and state-of-the-art language models.", <br/>
}
